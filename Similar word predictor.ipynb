{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad58749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5af8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Machine_learning')\n",
    "article = scrapped_data .read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7164286",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    import nltk\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "class PreProcessText(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __remove_punctuation(self, text):\n",
    "        \"\"\"\n",
    "        Takes a String\n",
    "        return : Return a String\n",
    "        \"\"\"\n",
    "        message = []\n",
    "        for x in text:\n",
    "            if x in string.punctuation:\n",
    "                pass\n",
    "            else:\n",
    "                message.append(x)\n",
    "        message = ''.join(message)\n",
    "\n",
    "        return message\n",
    "\n",
    "    def __remove_stopwords(self, text):\n",
    "        \"\"\"\n",
    "        Takes a String\n",
    "        return List\n",
    "        \"\"\"\n",
    "        words= []\n",
    "        for x in text.split():\n",
    "\n",
    "            if x.lower() in stopwords.words('english'):\n",
    "                pass\n",
    "            else:\n",
    "                words.append(x)\n",
    "        return words\n",
    "\n",
    "\n",
    "    def token_words(self,text=''):\n",
    "        \"\"\"\n",
    "        Takes String\n",
    "        Return Token also called  list of words that is used to\n",
    "        Train the Model\n",
    "        \"\"\"\n",
    "        message = self.__remove_punctuation(text)\n",
    "        words = self.__remove_stopwords(message)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9aa79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Danish\n",
      "[nltk_data]     private\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Stop words ...... \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "flag = nltk.download(\"stopwords\")\n",
    "\n",
    "if (flag == \"False\" or flag == False):\n",
    "    print(\"Failed to Download Stop Words\")\n",
    "else:\n",
    "    print(\"Downloaded Stop words ...... \")\n",
    "    helper = PreProcessText()\n",
    "    #words = helper.token_words(text=txt)\n",
    "    words = helper.token_words(text=article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766bcd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ffdfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.0-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Collecting Cython==0.29.32\n",
      "  Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "     -------------------------------------- 986.3/986.3 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.23.3)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.1/67.1 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danish private\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.9.24)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20431 sha256=f93a123fb74c5b92a497a9c845ea543a43640105e934f0d20f2cbd676005e4d7\n",
      "  Stored in directory: c:\\users\\danish private\\appdata\\local\\pip\\cache\\wheels\\01\\02\\ee\\df0699282986903a384b69aab4413af9efd26b3612b5dccc9e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3514 sha256=9aed6eeb3541d6d707d4ca5d4a3a8ebef23eb0fa324da49ddf3e96e699bc55e3\n",
      "  Stored in directory: c:\\users\\danish private\\appdata\\local\\pip\\cache\\wheels\\43\\aa\\48\\5c66b931ff013ad19774081aa19656637af5c0cc33b5494b30\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: Cython, simpful, miniful, fst-pso, pyfume, FuzzyTM, gensim\n",
      "Successfully installed Cython-0.29.32 FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 simpful-2.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce82a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec([words], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc55ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_index = model.wv.key_to_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f11a620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 0.36174276471138),\n",
       " ('Google79', 0.3413509428501129),\n",
       " ('AIpowered', 0.3350885212421417),\n",
       " ('wellvisible', 0.3162895441055298),\n",
       " ('placeholder', 0.3124183416366577),\n",
       " ('sequence', 0.30940836668014526),\n",
       " ('mitigate', 0.3068401515483856),\n",
       " ('biases124125', 0.28612810373306274),\n",
       " ('sent', 0.2830638289451599),\n",
       " ('result', 0.2740645706653595)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c3255cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(vector_size=100,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896089a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
